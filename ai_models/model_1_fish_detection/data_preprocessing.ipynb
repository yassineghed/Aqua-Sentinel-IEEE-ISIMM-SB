{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpSml697D1ih",
        "outputId": "8fc4e99f-3c02-47b1-f178-d540823dbaab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EpoowPRFWgs",
        "outputId": "e4788691-5ddd-47a3-c90b-da3dc11c8a8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "PyTorch version: 2.9.0+cu126\n",
            "GPU available: True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import ultralytics\n",
        "\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"GPU available:\", torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlCMzH0K5OwQ",
        "outputId": "7a012ab2-b001-4dde-b891-dcb0a84d0237"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Current folder: /content/drive/MyDrive/Sight_Challenge/finger_crossed/train\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DATASET_DIR = \"/content/drive/MyDrive/Sight_Challenge/finger_crossed/train\"\n",
        "IMAGES_DIR = os.path.join(DATASET_DIR, \"images\")\n",
        "LABELS_DIR = os.path.join(DATASET_DIR, \"labels\")\n",
        "os.chdir(DATASET_DIR)\n",
        "\n",
        "print(\"Current folder:\", os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vErVkW20-R6X"
      },
      "outputs": [],
      "source": [
        "# preparing the multilabel matrix\n",
        "import numpy as np\n",
        "\n",
        "num_classes = 8\n",
        "\n",
        "image_paths = []\n",
        "labels_matrix = []\n",
        "for filename in sorted(os.listdir(IMAGES_DIR)):\n",
        "    if not filename.lower().endswith((\".jpg\",\".jpeg\",\".png\")):\n",
        "        continue\n",
        "\n",
        "    img_path = os.path.join(IMAGES_DIR, filename)\n",
        "    label_path = os.path.join(LABELS_DIR, filename.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "    image_paths.append(img_path)\n",
        "\n",
        "    multilabel = np.zeros(num_classes)\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for line in f:\n",
        "                cls = int(line.split()[0])\n",
        "                multilabel[cls] = 1\n",
        "\n",
        "    labels_matrix.append(multilabel)\n",
        "\n",
        "labels_matrix = np.array(labels_matrix)\n",
        "\n",
        "print(\"Total images:\", len(image_paths))\n",
        "print(\"Labels matrix shape:\", labels_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0hIh7M5BrQx"
      },
      "outputs": [],
      "source": [
        "!pip install -q iterative-stratification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k73d1siGCikO",
        "outputId": "d2f2b769-dbcb-44e4-fab5-031d8bc1e1e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images found: 1050\n",
            "Train size: 734\n",
            "Temp size : 316\n",
            "\n",
            "FINAL SPLIT SIZES:\n",
            "Train: 734\n",
            "Val  : 210\n",
            "Test : 106\n",
            "\n",
            "CLASS DISTRIBUTION CHECK:\n",
            "Train class counts: [        153          88         412         532         106         109         121         173]\n",
            "Val   class counts: [         44          25         118         152          30          31          35          49]\n",
            "Test  class counts: [         22          13          59          77          15          16          17          25]\n"
          ]
        }
      ],
      "source": [
        "# Multilabel stratified splitting Step\n",
        "import os\n",
        "import numpy as np\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
        "\n",
        "\n",
        "num_images = len(image_paths)\n",
        "print(\"Total images found:\", num_images)\n",
        "\n",
        "\n",
        "train_size = 0.70\n",
        "val_size   = 0.20\n",
        "test_size  = 0.10\n",
        "\n",
        "assert abs((train_size + val_size + test_size) - 1.0) < 1e-6, \"Splits must sum to 1.\"\n",
        "\n",
        "# 1st SPLIT: Train vs Temp (val+test together)\n",
        "\n",
        "msss_train = MultilabelStratifiedShuffleSplit(\n",
        "    n_splits=1,\n",
        "    test_size=(1 - train_size),\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "for train_idx, temp_idx in msss_train.split(image_paths, labels_matrix):\n",
        "    pass\n",
        "\n",
        "print(\"Train size:\", len(train_idx))\n",
        "print(\"Temp size :\", len(temp_idx))\n",
        "\n",
        "# 2sd SPLIT: Temp -> Val + Test\n",
        "\n",
        "relative_test_size = test_size / (val_size + test_size)\n",
        "\n",
        "msss_val_test = MultilabelStratifiedShuffleSplit(\n",
        "    n_splits=1,\n",
        "    test_size=relative_test_size,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "temp_labels = labels_matrix[temp_idx]\n",
        "\n",
        "for val_idx, test_idx in msss_val_test.split(\n",
        "        np.array(image_paths)[temp_idx], temp_labels):\n",
        "    pass\n",
        "\n",
        "val_idx  = temp_idx[val_idx]\n",
        "test_idx = temp_idx[test_idx]\n",
        "\n",
        "\n",
        "print(\"\\nFINAL SPLIT SIZES:\")\n",
        "print(\"Train:\", len(train_idx))\n",
        "print(\"Val  :\", len(val_idx))\n",
        "print(\"Test :\", len(test_idx))\n",
        "\n",
        "# Checking class distribution balance\n",
        "\n",
        "def class_counts(split_idx):\n",
        "    subset = labels_matrix[split_idx]\n",
        "    return subset.sum(axis=0)\n",
        "\n",
        "print(\"\\nCLASS DISTRIBUTION CHECK:\")\n",
        "print(\"Train class counts:\", class_counts(train_idx))\n",
        "print(\"Val   class counts:\", class_counts(val_idx))\n",
        "print(\"Test  class counts:\", class_counts(test_idx))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fT-5SXQuLVZh"
      },
      "outputs": [],
      "source": [
        "#COPYING FILES TO DRIVE\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "FINAL_BASE = \"/content/drive/MyDrive/Sight Challenge/new-change-final\"\n",
        "\n",
        "splits = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "# Create folder structure\n",
        "for split in splits:\n",
        "    os.makedirs(f\"{FINAL_BASE}/{split}/images\", exist_ok=True)\n",
        "    os.makedirs(f\"{FINAL_BASE}/{split}/labels\", exist_ok=True)\n",
        "\n",
        "def copy_file(src, dst):\n",
        "    \"\"\"Safely copy file if it exists.\"\"\"\n",
        "    if os.path.exists(src):\n",
        "        shutil.copy(src, dst)\n",
        "\n",
        "# COPYING FILES\n",
        "\n",
        "def process_split(indices, split_name):\n",
        "    for idx in indices:\n",
        "        img_path = image_paths[idx]\n",
        "        filename = os.path.basename(img_path)\n",
        "\n",
        "        if not filename.lower().endswith(\".jpg\"):\n",
        "            continue\n",
        "\n",
        "        label_path = os.path.join(LABELS_DIR, filename.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "        # Destination folders\n",
        "        img_dst = f\"{FINAL_BASE}/{split_name}/images/{filename}\"\n",
        "        label_dst = f\"{FINAL_BASE}/{split_name}/labels/{filename.replace('.jpg', '.txt')}\"\n",
        "\n",
        "        # Copy files\n",
        "        copy_file(img_path, img_dst)\n",
        "        copy_file(label_path, label_dst)\n",
        "\n",
        "\n",
        "process_split(train_idx, \"train\")\n",
        "process_split(val_idx, \"val\")\n",
        "process_split(test_idx, \"test\")\n",
        "\n",
        "print(\"Dataset is copied into YOLO format!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flHG52iV6h0G"
      },
      "source": [
        "Augemnation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0T_1BBoX6kzm",
        "outputId": "d9de469a-a445-4192-e123-4d61b499bdea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting albumentations==1.4.3\n",
            "  Downloading albumentations-1.4.3-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.3) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.3) (1.16.3)\n",
            "Requirement already satisfied: scikit-image>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.3) (0.25.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.3) (6.0.3)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.3) (4.15.0)\n",
            "Requirement already satisfied: scikit-learn>=1.3.2 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.3) (1.6.1)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from albumentations==1.4.3) (4.12.0.88)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.3) (3.6)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.3) (11.3.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.3) (2.37.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.3) (2025.10.16)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.3) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.21.0->albumentations==1.4.3) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.3) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.3.2->albumentations==1.4.3) (3.6.0)\n",
            "Downloading albumentations-1.4.3-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 2.0.8\n",
            "    Uninstalling albumentations-2.0.8:\n",
            "      Successfully uninstalled albumentations-2.0.8\n",
            "Successfully installed albumentations-1.4.3\n"
          ]
        }
      ],
      "source": [
        "!pip install albumentations==1.4.3 opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbVe1np161Qm",
        "outputId": "b9529708-d614-43a2-9f7c-6c4f9abdd59b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 734/734 [01:30<00:00,  8.12it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DONE — realistic marine augmentations saved!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# applying realistic marine DATA AUGMENTATIONS to the train datset\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import albumentations as A\n",
        "\n",
        "IMG_DIR = \"/content/drive/MyDrive/Sight_Challenge/last_try/train/images\"\n",
        "LBL_DIR = \"/content/drive/MyDrive/Sight_Challenge/last_try/train/labels\"\n",
        "\n",
        "OUT_IMG = \"/content/drive/MyDrive/Sight_Challenge/last_try/augmented/images\"\n",
        "OUT_LBL = \"/content/drive/MyDrive/Sight_Challenge/last_try/augmented/labels\"\n",
        "\n",
        "os.makedirs(OUT_IMG, exist_ok=True)\n",
        "os.makedirs(OUT_LBL, exist_ok=True)\n",
        "\n",
        "def read_label(path):\n",
        "    boxes = []\n",
        "    if not os.path.exists(path):\n",
        "        return boxes\n",
        "\n",
        "    with open(path, \"r\") as f:\n",
        "        for line in f:\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) < 5:\n",
        "                continue\n",
        "            c, x, y, w, h = map(float, parts[:5])\n",
        "            boxes.append([x, y, w, h, int(c)])\n",
        "    return boxes\n",
        "\n",
        "def clip_boxes(boxes):\n",
        "    clipped = []\n",
        "    for x, y, w, h, c in boxes:\n",
        "        x_min = max(0, x - w/2)\n",
        "        y_min = max(0, y - h/2)\n",
        "        x_max = min(1, x + w/2)\n",
        "        y_max = min(1, y + h/2)\n",
        "\n",
        "        new_w = max(0, x_max - x_min)\n",
        "        new_h = max(0, y_max - y_min)\n",
        "        new_x = x_min + new_w/2\n",
        "        new_y = y_min + new_h/2\n",
        "\n",
        "        clipped.append([new_x, new_y, new_w, new_h, c])\n",
        "    return clipped\n",
        "\n",
        "rare_aug_pool = A.Compose([\n",
        "    A.ColorJitter(brightness=0.17, contrast=0.17, saturation=0.17, hue=0.03, p=0.4),\n",
        "\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "\n",
        "    A.Rotate(limit=5, border_mode=cv2.BORDER_CONSTANT, p=0.35),\n",
        "\n",
        "    A.HorizontalFlip(p=0.4),\n",
        "\n",
        "    A.GaussianBlur(blur_limit=2, p=0.11),\n",
        "\n",
        "    A.CLAHE(clip_limit=2, p=0.15),\n",
        "],\n",
        "    bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])\n",
        ")\n",
        "\n",
        "common_aug_pool = A.Compose([\n",
        "    A.ColorJitter(brightness=0.17, contrast=0.17, saturation=0.17, hue=0.03, p=0.4),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.Rotate(limit=3, border_mode=cv2.BORDER_CONSTANT, p=0.25),\n",
        "    A.HorizontalFlip(p=0.3),\n",
        "    A.GaussianBlur(blur_limit=2, p=0.11),\n",
        "],\n",
        "    bbox_params=A.BboxParams(format=\"yolo\", label_fields=[\"class_labels\"])\n",
        ")\n",
        "\n",
        "RARE_CLASSES = {1, 4, 5, 6}\n",
        "\n",
        "image_files = [f for f in os.listdir(IMG_DIR) if f.endswith(\".jpg\")]\n",
        "\n",
        "for img_name in tqdm(image_files):\n",
        "    img_path = os.path.join(IMG_DIR, img_name)\n",
        "    lbl_path = os.path.join(LBL_DIR, img_name.replace(\".jpg\", \".txt\"))\n",
        "\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        continue\n",
        "\n",
        "    boxes = read_label(lbl_path)\n",
        "    boxes = clip_boxes(boxes)\n",
        "\n",
        "    if len(boxes) == 0:\n",
        "        continue\n",
        "\n",
        "    bboxes = [b[:4] for b in boxes]\n",
        "    class_labels = [b[4] for b in boxes]\n",
        "\n",
        "    contains_rare = any(c in RARE_CLASSES for c in class_labels)\n",
        "\n",
        "    # realistic numbers\n",
        "    num_augs = random.randint(2, 3) if contains_rare else random.randint(1, 2)\n",
        "\n",
        "    for i in range(num_augs):\n",
        "        pipeline = rare_aug_pool if contains_rare else common_aug_pool\n",
        "\n",
        "        augmented = pipeline(image=image, bboxes=bboxes, class_labels=class_labels)\n",
        "\n",
        "        aug_img = augmented[\"image\"]\n",
        "        aug_boxes = augmented[\"bboxes\"]\n",
        "        aug_labels = augmented[\"class_labels\"]\n",
        "\n",
        "        out_img_name = img_name.replace(\".jpg\", f\"_aug{i}.jpg\")\n",
        "        out_lbl_name = img_name.replace(\".jpg\", f\"_aug{i}.txt\")\n",
        "\n",
        "        cv2.imwrite(os.path.join(OUT_IMG, out_img_name), aug_img)\n",
        "\n",
        "        with open(os.path.join(OUT_LBL, out_lbl_name), \"w\") as f:\n",
        "            for bb, cls in zip(aug_boxes, aug_labels):\n",
        "                x, y, w, h = bb\n",
        "                f.write(f\"{cls} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\\n\")\n",
        "\n",
        "print(\"DONE — realistic marine augmentations saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3olnHokMdeSJ",
        "outputId": "ce632542-cf22-4357-a164-5d21393f9de1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train/images: 734 files\n",
            "train/labels: 734 files\n",
            "val/images: 210 files\n",
            "val/labels: 210 files\n",
            "augmented/images: 1314 files\n",
            "augmented/labels: 1314 files\n",
            "test/images: 106 files\n",
            "test/labels: 106 files\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/Sight_Challenge/last_try\"\n",
        "\n",
        "folders = [\n",
        "    \"train/images\",\n",
        "    \"train/labels\",\n",
        "    \"val/images\",\n",
        "    \"val/labels\",\n",
        "    \"augmented/images\",\n",
        "    \"augmented/labels\",\n",
        "    \"test/images\",\n",
        "    \"test/labels\"\n",
        "]\n",
        "\n",
        "for f in folders:\n",
        "    path = os.path.join(BASE, f)\n",
        "    count = len([x for x in os.listdir(path) if not x.startswith('.')])\n",
        "    print(f\"{f}: {count} files\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJz5FgGZ0xIA",
        "outputId": "798706d7-2e75-400a-b88b-c64b1f7f2234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final dataset structure created!\n",
            "All files copied into /Sight_Challenge/final_test successfully!\n"
          ]
        }
      ],
      "source": [
        "#All files copied into a final DATASET DIRECTORY\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "FINAL_DATASET = \"/content/drive/MyDrive/Sight_Challenge/final_test\"\n",
        "\n",
        "TRAIN_IMAGES = os.path.join(FINAL_DATASET, \"train/images\")\n",
        "TRAIN_LABELS = os.path.join(FINAL_DATASET, \"train/labels\")\n",
        "\n",
        "VAL_IMAGES = os.path.join(FINAL_DATASET, \"val/images\")\n",
        "VAL_LABELS = os.path.join(FINAL_DATASET, \"val/labels\")\n",
        "\n",
        "TEST_IMAGES = os.path.join(FINAL_DATASET, \"test/images\")\n",
        "TEST_LABELS = os.path.join(FINAL_DATASET, \"test/labels\")\n",
        "\n",
        "# Create folders\n",
        "for d in [TRAIN_IMAGES, TRAIN_LABELS, VAL_IMAGES, VAL_LABELS, TEST_IMAGES, TEST_LABELS]:\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "print(\"Final dataset structure created!\")\n",
        "\n",
        "\n",
        "ORIG_TRAIN_IMAGES = \"/content/drive/MyDrive/Sight_Challenge/last_try/train/images\"\n",
        "ORIG_TRAIN_LABELS = \"/content/drive/MyDrive/Sight_Challenge/last_try/train/labels\"\n",
        "\n",
        "# AUGMENTED FOLDERS\n",
        "AUG_IMAGES = \"/content/drive/MyDrive/Sight_Challenge/last_try/augmented/images\"\n",
        "AUG_LABELS = \"/content/drive/MyDrive/Sight_Challenge/last_try/augmented/labels\"\n",
        "\n",
        "# VAL + TEST ORIGINAL\n",
        "ORIG_VAL_IMAGES = \"/content/drive/MyDrive/Sight_Challenge/last_try/val/images\"\n",
        "ORIG_VAL_LABELS = \"/content/drive/MyDrive/Sight_Challenge/last_try/val/labels\"\n",
        "\n",
        "ORIG_TEST_IMAGES = \"/content/drive/MyDrive/Sight_Challenge/last_try/test/images\"\n",
        "ORIG_TEST_LABELS = \"/content/drive/MyDrive/Sight_Challenge/last_try/test/labels\"\n",
        "\n",
        "\n",
        "def copy_all(src, dst):\n",
        "    for f in os.listdir(src):\n",
        "        shutil.copy(os.path.join(src, f), os.path.join(dst, f))\n",
        "\n",
        "# Copy original train\n",
        "copy_all(ORIG_TRAIN_IMAGES, TRAIN_IMAGES)\n",
        "copy_all(ORIG_TRAIN_LABELS, TRAIN_LABELS)\n",
        "\n",
        "# Copy augmented train\n",
        "copy_all(AUG_IMAGES, TRAIN_IMAGES)\n",
        "copy_all(AUG_LABELS, TRAIN_LABELS)\n",
        "\n",
        "# Copy val\n",
        "copy_all(ORIG_VAL_IMAGES, VAL_IMAGES)\n",
        "copy_all(ORIG_VAL_LABELS, VAL_LABELS)\n",
        "\n",
        "# Copy test\n",
        "copy_all(ORIG_TEST_IMAGES, TEST_IMAGES)\n",
        "copy_all(ORIG_TEST_LABELS, TEST_LABELS)\n",
        "\n",
        "print(\"All files copied into /Sight_Challenge/final_test successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvKTmUHn4Lm4",
        "outputId": "9db16e43-09eb-4593-b3c5-e0b52d47ccab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train/images: 2048 files\n",
            "train/labels: 2048 files\n",
            "val/images: 210 files\n",
            "val/labels: 210 files\n",
            "test/images: 106 files\n",
            "test/labels: 106 files\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "BASE = \"/content/drive/MyDrive/Sight_Challenge/final_test\"\n",
        "\n",
        "folders = [\n",
        "    \"train/images\",\n",
        "    \"train/labels\",\n",
        "    \"val/images\",\n",
        "    \"val/labels\",\n",
        "    \"test/images\",\n",
        "    \"test/labels\"\n",
        "]\n",
        "\n",
        "for f in folders:\n",
        "    path = os.path.join(BASE, f)\n",
        "    count = len([x for x in os.listdir(path) if not x.startswith('.')])\n",
        "    print(f\"{f}: {count} files\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}